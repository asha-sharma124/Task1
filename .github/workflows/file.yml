# name: Production ASG Progressive Canary Deployment

# on:
#   push:
#     branches: [main]
#   workflow_dispatch:

# env:
#   AWS_REGION: ap-south-1
#   APP_NAME: quotes-app
#   OLD_ASG_NAME: ${{ secrets.OLD_ASG_NAME }}       # Updated dynamically after deployment
#   OLD_TG_ARN: ${{ secrets.OLD_TG_ARN }}           # Updated dynamically after deployment
#   ALB_LISTENER_ARN: ${{ secrets.ALB_LISTENER_ARN }}
#   LAUNCH_TEMPLATE_ID: ${{ secrets.LAUNCH_TEMPLATE_ID }}
#   PRIVATE_SUBNET_IDS: ${{ secrets.PRIVATE_SUBNET_IDS }}  # Ensure plural and comma-separated
#   DEPLOYMENT_BUCKET: ${{ secrets.DEPLOYMENT_BUCKET }}
#   SECURITY_GROUP_IDS: ${{ secrets.SECURITY_GROUP_IDS }}
#   TOTAL_INSTANCES: 4

# jobs:
#   build:
#     runs-on: ubuntu-latest
#     outputs:
#       image_tag: ${{ steps.set_tag.outputs.image_tag }}
#       launch_template_version: ${{ steps.create_lt_version.outputs.version }}
#     steps:
#       - name: Checkout code
#         uses: actions/checkout@v3

#       - name: Set image tag
#         id: set_tag
#         run: |
#           TAG=$(date +'%Y%m%d%H%M%S')
#           echo "image_tag=$TAG" >> $GITHUB_OUTPUT
         
#       - name: Set up Docker Buildx
#         uses: docker/setup-buildx-action@v2

#       - name: Login to Docker Hub
#         uses: docker/login-action@v2
#         with:
#           username: ${{ secrets.DOCKER_USERNAME }}
#           password: ${{ secrets.DOCKER_PASSWORD }}

#       - name: Build and push Docker images
#         run: |
#           TAG=${{ steps.set_tag.outputs.image_tag }}
#           echo "ðŸ—ï¸ Building images with tag: $TAG"
          
#           for service in db api app; do
#             IMAGE_NAME="${{ secrets.DOCKER_USERNAME }}/quotes-${service}"
#             echo "Building $service..."
#             docker build --no-cache -t $IMAGE_NAME:${TAG} -t $IMAGE_NAME:latest $GITHUB_WORKSPACE/$service
#             docker push $IMAGE_NAME:${TAG}
#             docker push $IMAGE_NAME:latest
#           done

#       - name: Configure AWS credentials
#         uses: aws-actions/configure-aws-credentials@v2
#         with:
#           aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws-region: ${{ env.AWS_REGION }}

#       - name: Upload deployment files to S3
#         run: |
#           TAG=${{ steps.set_tag.outputs.image_tag }}
          
#           sed -i "s|build: ./db|image: ${{ secrets.DOCKER_USERNAME }}/quotes-db:${TAG}|g" docker-compose.yml
#           sed -i "s|build: ./api|image: ${{ secrets.DOCKER_USERNAME }}/quotes-api:${TAG}|g" docker-compose.yml
#           sed -i "s|build: ./app|image: ${{ secrets.DOCKER_USERNAME }}/quotes-app:${TAG}|g" docker-compose.yml

#           aws s3 cp docker-compose.yml s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/
#           aws s3 cp deployment/ s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/deployment/ --recursive
#           aws s3 cp ./nginx-config/quotes.conf s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/

#           echo "âœ… Deployment files uploaded to S3"

#       - name: Create new Launch Template version with env setup and deploy
#         id: create_lt_version
#         run: |
#           TAG=${{ steps.set_tag.outputs.image_tag }}
          
#           cat > user-data.sh <<'EOF'
#           #!/bin/bash
#           set -ex

#           LOG_FILE=/var/log/user-data.log

#           echo "Starting system update..." | tee -a $LOG_FILE
#           sudo apt-get update -y >> $LOG_FILE 2>&1
#           sudo apt-get upgrade -y >> $LOG_FILE 2>&1

#           echo "Installing docker prerequisites..." | tee -a $LOG_FILE
#           sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common gnupg-agent >> $LOG_FILE 2>&1

#           echo "Adding Docker GPG key and repo..." | tee -a $LOG_FILE
#           curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - >> $LOG_FILE 2>&1
#           sudo add-apt-repository \
#             "deb [arch=$(dpkg --print-architecture)] https://download.docker.com/linux/ubuntu \
#             $(lsb_release -cs) stable" >> $LOG_FILE 2>&1

#           echo "Installing Docker engine..." | tee -a $LOG_FILE
#           sudo apt-get update -y >> $LOG_FILE 2>&1
#           sudo apt-get install -y docker-ce docker-ce-cli containerd.io >> $LOG_FILE 2>&1
#           sudo systemctl enable docker >> $LOG_FILE 2>&1
#           sudo systemctl start docker >> $LOG_FILE 2>&1

#           echo "Installing Docker Compose v2..." | tee -a $LOG_FILE
#           # Remove old docker-compose binary if any
#           sudo rm -f /usr/local/bin/docker-compose /usr/bin/docker-compose

#           # Install Docker Compose v2 plugin:
#           sudo apt-get install -y docker-compose-plugin


#           echo "Installing nginx..." | tee -a $LOG_FILE
#           sudo apt-get install -y nginx >> $LOG_FILE 2>&1
#           sudo systemctl enable nginx
#           sudo systemctl start nginx

#           echo "Installing AWS SSM agent..." | tee -a $LOG_FILE
#           if ! command -v snap >/dev/null 2>&1 || ! snap list amazon-ssm-agent >/dev/null 2>&1; then
#             echo "Installing Amazon SSM Agent via .deb package"
#             curl "https://s3.${AWS_REGION}.amazonaws.com/amazon-ssm-${AWS_REGION}/latest/debian_amd64/amazon-ssm-agent.deb" -o "amazon-ssm-agent.deb"
#             sudo dpkg -i amazon-ssm-agent.deb || sudo apt-get install -f -y
#             sudo systemctl enable amazon-ssm-agent
#             sudo systemctl start amazon-ssm-agent
#           else
#             echo "Amazon SSM Agent already installed via snap, skipping .deb install"
#             sudo systemctl enable snap.amazon-ssm-agent.amazon-ssm-agent.service
#             sudo systemctl start snap.amazon-ssm-agent.amazon-ssm-agent.service
#           fi
#           # Update package index and install prerequisites
#           sudo apt-get update -y
#           sudo apt-get install -y unzip curl

#           # Download the AWS CLI v2 installer zip
#           curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"

#           # Unzip the installer
#           unzip awscliv2.zip

#           # Run the install script
#           sudo ./aws/install

#           # Verify installation
#           aws --version

#           sudo usermod -aG docker ubuntu

#           echo "Creating app directory..." | tee -a $LOG_FILE
#           APP_DIR=/home/ubuntu/quotes-app
#           sudo mkdir -p $APP_DIR/deployment
#           sudo chown -R ubuntu:ubuntu $APP_DIR
#           echo "App directory created at $APP_DIR" | tee -a $LOG_FILE

#           echo "Downloading deployment files from S3..." | tee -a $LOG_FILE
#           aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${DEPLOYMENT_TAG}/docker-compose.yml $APP_DIR/docker-compose.yml --region ${AWS_REGION} >> $LOG_FILE 2>&1
#           aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${DEPLOYMENT_TAG}/deployment/ $APP_DIR/deployment/ --recursive --region ${AWS_REGION} >> $LOG_FILE 2>&1
#           sudo aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${DEPLOYMENT_TAG}/quotes.conf /etc/nginx/conf.d/quotes.conf --region ${AWS_REGION} >> $LOG_FILE 2>&1

#           sudo chown -R ubuntu:ubuntu $APP_DIR
#           sudo chmod +x $APP_DIR/deployment/*.sh

#           echo "Deploying docker-compose app..." | tee -a $LOG_FILE
#           cd $APP_DIR
#           sudo -u ubuntu docker compose down || true >> $LOG_FILE 2>&1
#           sudo -u ubuntu docker compose pull >> $LOG_FILE 2>&1
#           sudo -u ubuntu docker compose up -d >> $LOG_FILE 2>&1
#           sudo rm -rf /etc/nginx/sites-enabled/default
#           echo "Reloading nginx..." | tee -a $LOG_FILE
#           sudo systemctl reload nginx >> $LOG_FILE 2>&1

#           echo "User data script completed successfully" | tee -a $LOG_FILE

#           EOF

#           sed -i "s|\${DEPLOYMENT_BUCKET}|${{ env.DEPLOYMENT_BUCKET }}|g" user-data.sh
#           sed -i "s|\${DEPLOYMENT_TAG}|${TAG}|g" user-data.sh
#           sed -i "s|\${AWS_REGION}|${{ env.AWS_REGION }}|g" user-data.sh
#           sed -i "s|\${DOCKER_USERNAME}|${{ secrets.DOCKER_USERNAME }}|g" user-data.sh
#           sed -i "s|\${DOCKER_PASSWORD}|${{ secrets.DOCKER_PASSWORD }}|g" user-data.sh

#           NEW_VERSION=$(aws ec2 create-launch-template-version \
#             --launch-template-id ${{ env.LAUNCH_TEMPLATE_ID }} \
#             --source-version '$Latest' \
#             --launch-template-data "{
#               \"UserData\": \"$(base64 -w 0 user-data.sh)\",
#               \"TagSpecifications\": [{
#                 \"ResourceType\": \"instance\",
#                 \"Tags\": [
#                   {\"Key\": \"Name\", \"Value\": \"quotes-app-green\"},
#                   {\"Key\": \"Environment\", \"Value\": \"green\"},
#                   {\"Key\": \"DeploymentBatch\", \"Value\": \"${TAG}\"}
#                 ]
#               }]
#             }" \
#             --query 'LaunchTemplateVersion.VersionNumber' \
#             --output text)

#           echo "version=$NEW_VERSION" >> $GITHUB_OUTPUT
#           echo "âœ… Created Launch Template version: $NEW_VERSION"

#   create-new-infrastructure:
#     needs: build
#     runs-on: ubuntu-latest
#     outputs:
#       new_asg_name: ${{ steps.create-asg.outputs.asg_name }}
#       new_tg_arn: ${{ steps.create-tg.outputs.tg_arn }}
#     steps:
#       - name: Configure AWS credentials
#         uses: aws-actions/configure-aws-credentials@v2
#         with:
#           aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws-region: ${{ env.AWS_REGION }}

#       - name: Create new Target Group
#         id: create-tg
#         run: |
#           TG_NAME="tg-${{ github.run_number }}-${{ env.APP_NAME }}"
#           TG_ARN=$(aws elbv2 create-target-group \
#             --name "$TG_NAME" \
#             --protocol HTTP \
#             --port 80 \
#             --vpc-id "${{ secrets.VPC_ID }}" \
#             --health-check-path /health \
#             --health-check-interval-seconds 30 \
#             --health-check-timeout-seconds 5 \
#             --healthy-threshold-count 2 \
#             --unhealthy-threshold-count 3 \
#             --query 'TargetGroups[0].TargetGroupArn' \
#             --output text)
#           echo "tg_arn=$TG_ARN" >> $GITHUB_OUTPUT
#           echo "Created Target Group: $TG_NAME"

#       - name: Create new Auto Scaling Group
#         id: create-asg
#         run: |
#           ASG_NAME="asg-${{ github.run_number }}-${{ env.APP_NAME }}"
#           aws autoscaling create-auto-scaling-group \
#             --auto-scaling-group-name "$ASG_NAME" \
#             --launch-template LaunchTemplateId=${{ env.LAUNCH_TEMPLATE_ID }},Version=${{ needs.build.outputs.launch_template_version }} \
#             --min-size 1 \
#             --max-size 4 \
#             --desired-capacity 1 \
#             --target-group-arns "${{ steps.create-tg.outputs.tg_arn }}" \
#             --vpc-zone-identifier "${{ secrets.PRIVATE_SUBNET_IDS }}" \
#             --health-check-type ELB \
#             --health-check-grace-period 300 \
#             --termination-policies "OldestInstance" \
#             --tags Key=Name,Value="$ASG_NAME" Key=Environment,Value=green Key=DeploymentBatch,Value=${{ steps.set_tag.outputs.image_tag }}
#           echo "asg_name=$ASG_NAME" >> $GITHUB_OUTPUT
#           echo "Created ASG: $ASG_NAME"
#           sleep 300

#       - name: Set initial traffic split 80% old TG, 20% new TG
#         run: |
#          aws elbv2 modify-listener \
#           --listener-arn ${{ env.ALB_LISTENER_ARN }} \
#           --default-actions '[
#             {
#               "Type": "forward",
#               "ForwardConfig": {
#                 "TargetGroups": [
#                   {
#                     "TargetGroupArn": "${{ env.OLD_TG_ARN }}",
#                     "Weight": 80
#                   },
#                   {
#                     "TargetGroupArn": "${{ steps.create-tg.outputs.tg_arn }}",
#                     "Weight": 20
#                   }
#                 ],
#                 "TargetGroupStickinessConfig": {
#                   "Enabled": false
#                 }
#               }
#             }
#           ]'
#           echo "Traffic split set to 80% old, 20% new"

          

# # Add your qa-approval, progressive-rollout, and update-secrets jobs as before here...

#   qa-approval:
#     needs: create-new-infrastructure
#     runs-on: ubuntu-latest
#     environment:
#       name: production-approval
#     steps:
#       - run: |
#           echo "QA testing period: 20 mins"
          

#   progressive-rollout:
#     needs: [create-new-infrastructure, qa-approval]
#     runs-on: ubuntu-latest
#     steps:
#       - name: Configure AWS credentials
#         uses: aws-actions/configure-aws-credentials@v2
#         with:
#           aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws-region: ${{ env.AWS_REGION }}

#       - name: Iteration 1 - Scale new ASG to 2 and update traffic 50/50
#         run: |
#           aws autoscaling set-desired-capacity --auto-scaling-group-name ${{ needs.create-new-infrastructure.outputs.new_asg_name }} --desired-capacity 2
#           sleep 180
#           aws elbv2 modify-listener --listener-arn ${{ env.ALB_LISTENER_ARN }} --default-actions Type=forward,ForwardConfig="{
#             TargetGroups:[
#               {TargetGroupArn='${{ env.OLD_TG_ARN }}',Weight=50},
#               {TargetGroupArn='${{ needs.create-new-infrastructure.outputs.new_tg_arn }}',Weight=50}
#             ]
#           }"
#           aws autoscaling set-desired-capacity --auto-scaling-group-name ${{ env.OLD_ASG_NAME }} --desired-capacity 3

#       - name: Wait and monitor
#         run: sleep 300

#       - name: Iteration 2 - Scale new ASG to 3 and update traffic 60/40
#         run: |
#           aws autoscaling set-desired-capacity --auto-scaling-group-name ${{ needs.create-new-infrastructure.outputs.new_asg_name }} --desired-capacity 3
#           sleep 180
#           aws elbv2 modify-listener --listener-arn ${{ env.ALB_LISTENER_ARN }} --default-actions Type=forward,ForwardConfig="{
#             TargetGroups:[
#               {TargetGroupArn='${{ env.OLD_TG_ARN }}',Weight=40},
#               {TargetGroupArn='${{ needs.create-new-infrastructure.outputs.new_tg_arn }}',Weight=60}
#             ]
#           }"
#           aws autoscaling set-desired-capacity --auto-scaling-group-name ${{ env.OLD_ASG_NAME }} --desired-capacity 2

#       - name: Wait and monitor
#         run: sleep 300

#       - name: Iteration 3 - Scale new ASG to 4 and update traffic 80/20
#         run: |
#           aws autoscaling set-desired-capacity --auto-scaling-group-name ${{ needs.create-new-infrastructure.outputs.new_asg_name }} --desired-capacity 4
#           sleep 180
#           aws elbv2 modify-listener --listener-arn ${{ env.ALB_LISTENER_ARN }} --default-actions Type=forward,ForwardConfig="{
#             TargetGroups:[
#               {TargetGroupArn='${{ env.OLD_TG_ARN }}',Weight=20},
#               {TargetGroupArn='${{ needs.create-new-infrastructure.outputs.new_tg_arn }}',Weight=80}
#             ]
#           }"
#           aws autoscaling set-desired-capacity --auto-scaling-group-name ${{ env.OLD_ASG_NAME }} --desired-capacity 1

#       - name: Wait and monitor
#         run: sleep 300

#       - name: Final Cutover - 100% to new ASG
#         run: |
#           aws elbv2 modify-listener --listener-arn ${{ env.ALB_LISTENER_ARN }} --default-actions Type=forward,TargetGroupArn=${{ needs.create-new-infrastructure.outputs.new_tg_arn }}
#           sleep 60
#           aws autoscaling update-auto-scaling-group --auto-scaling-group-name ${{ env.OLD_ASG_NAME }} --min-size 0 --desired-capacity 0
#           aws autoscaling delete-auto-scaling-group --auto-scaling-group-name ${{ env.OLD_ASG_NAME }} --force-delete
#           aws elbv2 delete-target-group --target-group-arn ${{ env.OLD_TG_ARN }}

#   update-secrets:
#     needs: progressive-rollout
#     runs-on: ubuntu-latest
#     steps:
#       - name: Update OLD_ASG_NAME secret
#         uses: peter-evans/create-or-update-secret@v1
#         with:
#           secret-name: OLD_ASG_NAME
#           secret-value: ${{ needs.create-new-infrastructure.outputs.new_asg_name }}
#           repository: ${{ github.repository }}
#           token: ${{ secrets.GH_PAT }}

#       - name: Update OLD_TG_ARN secret
#         uses: peter-evans/create-or-update-secret@v1
#         with:
#           secret-name: OLD_TG_ARN
#           secret-value: ${{ needs.create-new-infrastructure.outputs.new_tg_arn }}
#           repository: ${{ github.repository }}
#           token: ${{ secrets.GH_PAT }}

# # Note:
# # - GH_PAT is a GitHub Personal Access Token with repo and admin:repo_hook scopes set as a secret.
# # - Ensure all required secrets (VPC_ID, LAUNCH_TEMPLATE_ID, DEPLOYMENT_BUCKET, etc.) are defined properly.

# name: Production ASG Progressive Canary Deployment

# on:
#   push:
#     branches: [main]
#   workflow_dispatch:

# env:
#   AWS_REGION: ap-south-1
#   APP_NAME: quotes-app
#   OLD_ASG_NAME: ${{ secrets.OLD_ASG_NAME }}
#   OLD_TG_ARN: ${{ secrets.OLD_TG_ARN }}
#   ALB_LISTENER_ARN: ${{ secrets.ALB_LISTENER_ARN }}
#   LAUNCH_TEMPLATE_ID: ${{ secrets.LAUNCH_TEMPLATE_ID }}
#   PRIVATE_SUBNET_IDS: ${{ secrets.PRIVATE_SUBNET_IDS }}
#   DEPLOYMENT_BUCKET: ${{ secrets.DEPLOYMENT_BUCKET }}
#   SECURITY_GROUP_IDS: ${{ secrets.SECURITY_GROUP_IDS }}
#   TOTAL_INSTANCES: 5

# jobs:
#   build:
#     runs-on: ubuntu-latest
#     outputs:
#       image_tag: ${{ steps.set_tag.outputs.image_tag }}
#       launch_template_version: ${{ steps.create_lt_version.outputs.version }}
#     steps:
#       - name: Checkout code
#         uses: actions/checkout@v3

#       - name: Set image tag
#         id: set_tag
#         run: |
#           TAG=$(date +'%Y%m%d%H%M%S')
#           echo "image_tag=$TAG" >> $GITHUB_OUTPUT
         
#       - name: Set up Docker Buildx
#         uses: docker/setup-buildx-action@v2

#       - name: Login to Docker Hub
#         uses: docker/login-action@v2
#         with:
#           username: ${{ secrets.DOCKER_USERNAME }}
#           password: ${{ secrets.DOCKER_PASSWORD }}

#       - name: Build and push Docker images
#         run: |
#           TAG=${{ steps.set_tag.outputs.image_tag }}
#           echo " Building images with tag: $TAG"
          
#           for service in db api app; do
#             IMAGE_NAME="${{ secrets.DOCKER_USERNAME }}/quotes-${service}"
#             echo "Building $service..."
#             docker build --no-cache -t $IMAGE_NAME:${TAG} -t $IMAGE_NAME:latest $GITHUB_WORKSPACE/$service
#             docker push $IMAGE_NAME:${TAG}
#             docker push $IMAGE_NAME:latest
#           done

#       - name: Configure AWS credentials
#         uses: aws-actions/configure-aws-credentials@v2
#         with:
#           aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws-region: ${{ env.AWS_REGION }}

#       - name: Upload deployment files to S3
#         run: |
#           TAG=${{ steps.set_tag.outputs.image_tag }}
          
#           sed -i "s|build: ./db|image: ${{ secrets.DOCKER_USERNAME }}/quotes-db:${TAG}|g" docker-compose.yml
#           sed -i "s|build: ./api|image: ${{ secrets.DOCKER_USERNAME }}/quotes-api:${TAG}|g" docker-compose.yml
#           sed -i "s|build: ./app|image: ${{ secrets.DOCKER_USERNAME }}/quotes-app:${TAG}|g" docker-compose.yml

#           aws s3 cp docker-compose.yml s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/
#           aws s3 cp deployment/ s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/deployment/ --recursive
#           aws s3 cp ./nginx-config/quotes.conf s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/

#           echo "Deployment files uploaded to S3"

#       - name: Create new Launch Template version with env setup and deploy
#         id: create_lt_version
#         run: |
#           TAG=${{ steps.set_tag.outputs.image_tag }}
          
#           cat > user-data.sh <<'EOF'
#           #!/bin/bash
#           set -ex

#           LOG_FILE=/var/log/user-data.log

#           echo "Starting system update..." | tee -a $LOG_FILE
#           sudo apt-get update -y >> $LOG_FILE 2>&1
#           sudo apt-get upgrade -y >> $LOG_FILE 2>&1

#           echo "Installing docker prerequisites..." | tee -a $LOG_FILE
#           sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common gnupg-agent >> $LOG_FILE 2>&1

#           echo "Adding Docker GPG key and repo..." | tee -a $LOG_FILE
#           curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - >> $LOG_FILE 2>&1
#           sudo add-apt-repository \
#             "deb [arch=$(dpkg --print-architecture)] https://download.docker.com/linux/ubuntu \
#             $(lsb_release -cs) stable" >> $LOG_FILE 2>&1

#           echo "Installing Docker engine..." | tee -a $LOG_FILE
#           sudo apt-get update -y >> $LOG_FILE 2>&1
#           sudo apt-get install -y docker-ce docker-ce-cli containerd.io >> $LOG_FILE 2>&1
#           sudo systemctl enable docker >> $LOG_FILE 2>&1
#           sudo systemctl start docker >> $LOG_FILE 2>&1

#           echo "Installing Docker Compose v2..." | tee -a $LOG_FILE
#           sudo rm -f /usr/local/bin/docker-compose /usr/bin/docker-compose
#           sudo apt-get install -y docker-compose-plugin

#           echo "Installing nginx..." | tee -a $LOG_FILE
#           sudo apt-get install -y nginx >> $LOG_FILE 2>&1
#           sudo systemctl enable nginx
#           sudo systemctl start nginx

#           echo "Installing AWS SSM agent..." | tee -a $LOG_FILE
#           if ! command -v snap >/dev/null 2>&1 || ! snap list amazon-ssm-agent >/dev/null 2>&1; then
#             echo "Installing Amazon SSM Agent via .deb package"
#             curl "https://s3.${AWS_REGION}.amazonaws.com/amazon-ssm-${AWS_REGION}/latest/debian_amd64/amazon-ssm-agent.deb" -o "amazon-ssm-agent.deb"
#             sudo dpkg -i amazon-ssm-agent.deb || sudo apt-get install -f -y
#             sudo systemctl enable amazon-ssm-agent
#             sudo systemctl start amazon-ssm-agent
#           else
#             echo "Amazon SSM Agent already installed via snap, skipping .deb install"
#             sudo systemctl enable snap.amazon-ssm-agent.amazon-ssm-agent.service
#             sudo systemctl start snap.amazon-ssm-agent.amazon-ssm-agent.service
#           fi
          
#           sudo apt-get update -y
#           sudo apt-get install -y unzip curl

#           curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
#           unzip awscliv2.zip
#           sudo ./aws/install
#           aws --version

#           sudo usermod -aG docker ubuntu

#           echo "Creating app directory..." | tee -a $LOG_FILE
#           APP_DIR=/home/ubuntu/quotes-app
#           sudo mkdir -p $APP_DIR/deployment
#           sudo chown -R ubuntu:ubuntu $APP_DIR
#           echo "App directory created at $APP_DIR" | tee -a $LOG_FILE

#           echo "Downloading deployment files from S3..." | tee -a $LOG_FILE
#           aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/docker-compose.yml $APP_DIR/docker-compose.yml --region ${AWS_REGION} >> $LOG_FILE 2>&1
#           aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/deployment/ $APP_DIR/deployment/ --recursive --region ${AWS_REGION} >> $LOG_FILE 2>&1
#           sudo aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/quotes.conf /etc/nginx/conf.d/quotes.conf --region ${AWS_REGION} >> $LOG_FILE 2>&1

#           sudo chown -R ubuntu:ubuntu $APP_DIR
#           sudo chmod +x $APP_DIR/deployment/*.sh

#           echo "Deploying docker-compose app..." | tee -a $LOG_FILE
#           cd $APP_DIR
#           sudo -u ubuntu docker compose down || true >> $LOG_FILE 2>&1
#           sudo -u ubuntu docker compose pull >> $LOG_FILE 2>&1
#           sudo -u ubuntu docker compose up -d >> $LOG_FILE 2>&1
#           sudo rm -rf /etc/nginx/sites-enabled/default
#           echo "Reloading nginx..." | tee -a $LOG_FILE
#           sudo systemctl reload nginx >> $LOG_FILE 2>&1

#           echo "User data script completed successfully" | tee -a $LOG_FILE

#           EOF

#           sed -i "s|\${DEPLOYMENT_BUCKET}|${{ env.DEPLOYMENT_BUCKET }}|g" user-data.sh
#           sed -i "s|\${TAG}|${TAG}|g" user-data.sh
#           sed -i "s|\${AWS_REGION}|${{ env.AWS_REGION }}|g" user-data.sh
#           sed -i "s|\${DOCKER_USERNAME}|${{ secrets.DOCKER_USERNAME }}|g" user-data.sh
#           sed -i "s|\${DOCKER_PASSWORD}|${{ secrets.DOCKER_PASSWORD }}|g" user-data.sh

#           NEW_VERSION=$(aws ec2 create-launch-template-version \
#             --launch-template-id ${{ env.LAUNCH_TEMPLATE_ID }} \
#             --source-version '$Latest' \
#             --launch-template-data "{
#               \"UserData\": \"$(base64 -w 0 user-data.sh)\",
#               \"TagSpecifications\": [{
#                 \"ResourceType\": \"instance\",
#                 \"Tags\": [
#                   {\"Key\": \"Name\", \"Value\": \"quotes-app-green\"},
#                   {\"Key\": \"Environment\", \"Value\": \"green\"},
#                   {\"Key\": \"DeploymentBatch\", \"Value\": \"${TAG}\"}
#                 ]
#               }]
#             }" \
#             --query 'LaunchTemplateVersion.VersionNumber' \
#             --output text)

#           echo "version=$NEW_VERSION" >> $GITHUB_OUTPUT
#           echo "Created Launch Template version: $NEW_VERSION"

#   create-new-infrastructure:
#     needs: build
#     runs-on: ubuntu-latest
#     outputs:
#       new_asg_name: ${{ steps.create_asg.outputs.asg_name }}
#       new_tg_arn: ${{ steps.create_tg.outputs.tg_arn }}
#     steps:
#       - name: Configure AWS credentials
#         uses: aws-actions/configure-aws-credentials@v2
#         with:
#           aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws-region: ${{ env.AWS_REGION }}

#       - name: Create new Target Group
#         id: create_tg
#         run: |
#           TG_NAME="tg-${{ github.run_number }}-${{ env.APP_NAME }}"
#           TG_ARN=$(aws elbv2 create-target-group \
#             --name "$TG_NAME" \
#             --protocol HTTP \
#             --port 80 \
#             --vpc-id "${{ secrets.VPC_ID }}" \
#             --health-check-path / \
#             --health-check-interval-seconds 30 \
#             --health-check-timeout-seconds 5 \
#             --healthy-threshold-count 2 \
#             --unhealthy-threshold-count 3 \
#             --query 'TargetGroups[0].TargetGroupArn' \
#             --output text)
#           echo "tg_arn=$TG_ARN" >> $GITHUB_OUTPUT
#           echo "Created Target Group: $TG_ARN"
#           sleep 25

#       - name: Create new Auto Scaling Group
#         id: create_asg
#         run: |
#           ASG_NAME="asg-${{ github.run_number }}-${{ env.APP_NAME }}"
#           aws autoscaling create-auto-scaling-group \
#             --auto-scaling-group-name "$ASG_NAME" \
#             --launch-template LaunchTemplateId=${{ env.LAUNCH_TEMPLATE_ID }},Version=${{ needs.build.outputs.launch_template_version }} \
#             --min-size 1 \
#             --max-size 5 \
#             --desired-capacity 1 \
#             --target-group-arns "${{ steps.create_tg.outputs.tg_arn }}" \
#             --vpc-zone-identifier "${{ secrets.PRIVATE_SUBNET_IDS }}" \
#             --health-check-type ELB \
#             --health-check-grace-period 300 \
#             --termination-policies "OldestInstance" \
#             --tags Key=Name,Value="$ASG_NAME" Key=Environment,Value=green Key=DeploymentBatch,Value=${{ needs.build.outputs.image_tag }}
#           echo "asg_name=$ASG_NAME" >> $GITHUB_OUTPUT
#           sleep 50
#       - name: Debug create_tg output
#         run: echo "TG ARN from step= ${{ steps.create_tg.outputs.tg_arn }}"

#       - name: Set initial traffic split 80% old TG, 20% new TG
#         run: |
#           aws elbv2 modify-listener \
#             --listener-arn ${{ env.ALB_LISTENER_ARN }} \
#             --default-actions '[
#               {
#                 "Type": "forward",
#                 "ForwardConfig": {
#                   "TargetGroups": [
#                     {
#                       "TargetGroupArn": "${{ env.OLD_TG_ARN }}",
#                       "Weight": 80
#                     },
#                     {
#                       "TargetGroupArn": "${{ steps.create_tg.outputs.tg_arn }}",
#                       "Weight": 20
#                     }
#                   ],
#                   "TargetGroupStickinessConfig": {
#                     "Enabled": false
#                   }
#                 }
#               }
#             ]'
#           echo "Traffic split set to 80% old, 20% new"

#   qa-approval:
#     needs: create-new-infrastructure
#     runs-on: ubuntu-latest
#     environment:
#       name: production-approval
#     steps:
#       - run: |
#           echo "QA testing period: 20 mins"

#   progressive-rollout:
#     needs: [create-new-infrastructure, qa-approval]
#     runs-on: ubuntu-latest
#     env:
#       OLD_ASG_NAME: ${{ secrets.OLD_ASG_NAME }}
#       OLD_TG_ARN: ${{ secrets.OLD_TG_ARN }}
#       NEW_ASG_NAME: ${{ needs.create-new-infrastructure.outputs.new_asg_name }}
#       NEW_TG_ARN: ${{ needs.create-new-infrastructure.outputs.new_tg_arn }}
#       ALB_LISTENER_ARN: ${{ secrets.ALB_LISTENER_ARN }}
#       MAX_NEW_CAPACITY: 5
#     steps:
#       - name: Configure AWS credentials
#         uses: aws-actions/configure-aws-credentials@v2
#         with:
#           aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws-region: ${{ env.AWS_REGION }}

#       - name: Dynamic Traffic Shifting with Loop
#         run: |
#           echo "NEW_ASG_NAME=${NEW_ASG_NAME}"
#           echo "NEW_TG_ARN=${NEW_TG_ARN}"
#           echo "OLD_ASG_NAME=${OLD_ASG_NAME}"
#           echo "OLD_TG_ARN=${OLD_TG_ARN}"

#           set -e
        
#           echo "========================================="
#           echo "Starting Dynamic Progressive Deployment"
#           echo "========================================="
#           echo "NEW TG ARN inside script: $NEW_TG_ARN" 
#           if [ -z "$OLD_ASG_NAME" ] || [ "$OLD_ASG_NAME" == "null" ] || [ -z "$OLD_TG_ARN" ] || [ "$OLD_TG_ARN" == "null" ]; then
#             echo "First deployment detected - no old infrastructure to migrate from"
#             echo "New ASG: $NEW_ASG_NAME"
#             echo "Max Capacity: $MAX_NEW_CAPACITY"
#             echo "Scaling new ASG to $MAX_NEW_CAPACITY instances..."
#             aws autoscaling set-desired-capacity \
#               --auto-scaling-group-name "$NEW_ASG_NAME" \
#               --desired-capacity "$MAX_NEW_CAPACITY"

#             echo " Waiting for instances to become healthy..."
#             sleep 240

#             echo "Setting ALB listener to 100% new TG"
#             aws elbv2 modify-listener \
#               --listener-arn "$ALB_LISTENER_ARN" \
#               --default-actions Type=forward,TargetGroupArn="$NEW_TG_ARN"

#             echo " First deployment completed successfully!"
#             exit 0
#           fi

#           echo "Old ASG: $OLD_ASG_NAME"
#           echo "New ASG: $NEW_ASG_NAME"
#           echo "Max Capacity: $MAX_NEW_CAPACITY"
#           echo ""

#           count_healthy_instances() {
#             local TG_ARN=$1
#             if [ -z "$TG_ARN" ] || [ "$TG_ARN" == "null" ]; then
#               echo "0"
#               return
#             fi
#             aws elbv2 describe-target-health \
#               --target-group-arn "$TG_ARN" \
#               --query "length(TargetHealthDescriptions[?TargetHealth.State=='healthy'])" \
#               --output text 2>/dev/null || echo "0"
#           }

#           get_asg_capacity() {
#             local ASG_NAME=$1
#             if [ -z "$ASG_NAME" ] || [ "$ASG_NAME" == "null" ]; then
#               echo "0"
#               return
#             fi
#             aws autoscaling describe-auto-scaling-groups \
#               --auto-scaling-group-names "$ASG_NAME" \
#               --query "AutoScalingGroups[0].DesiredCapacity" \
#               --output text 2>/dev/null || echo "0"
#           }

#           update_traffic_weights() {
#             local OLD_WEIGHT=$1
#             local NEW_WEIGHT=$2
#             echo "Updating traffic: Old TG=${OLD_WEIGHT}%, New TG=${NEW_WEIGHT}%"
#             if [ "$OLD_WEIGHT" -eq 0 ]; then
#               aws elbv2 modify-listener \
#                 --listener-arn "$ALB_LISTENER_ARN" \
#                 --default-actions Type=forward,TargetGroupArn="$NEW_TG_ARN"
#             elif [ "$NEW_WEIGHT" -eq 0 ]; then
#               aws elbv2 modify-listener \
#                 --listener-arn "$ALB_LISTENER_ARN" \
#                 --default-actions Type=forward,TargetGroupArn="$OLD_TG_ARN"
#             else
#               aws elbv2 modify-listener \
#                 --listener-arn "$ALB_LISTENER_ARN" \
#                 --default-actions Type=forward,ForwardConfig="{
#                   TargetGroups:[
#                     {TargetGroupArn='$OLD_TG_ARN',Weight=$OLD_WEIGHT},
#                     {TargetGroupArn='$NEW_TG_ARN',Weight=$NEW_WEIGHT}
#                   ]
#                 }"
#             fi
#           }

#           ITERATION=1
#           while true; do
#             echo ""
#             echo "========================================="
#             echo "ðŸ“ Iteration $ITERATION"
#             echo "========================================="
#             echo "NEW TG = $NEW_TG_ARN"
#             OLD_CAPACITY=$(get_asg_capacity "$OLD_ASG_NAME")
#             NEW_CAPACITY=$(get_asg_capacity "$NEW_ASG_NAME")

#             echo "Current capacities: Old ASG=$OLD_CAPACITY, New ASG=$NEW_CAPACITY"

#             if [ "$NEW_CAPACITY" -ge "$MAX_NEW_CAPACITY" ]; then
#               echo " New ASG has reached maximum capacity ($MAX_NEW_CAPACITY)"
#               echo " Performing final traffic shift to 100% new TG"
#               update_traffic_weights 0 100
#               echo " Waiting 3 minutes for traffic to stabilize..."
#               sleep 180
#               NEW_HEALTHY_FINAL=$(count_healthy_instances "$NEW_TG_ARN")
#               echo "Final health check: $NEW_HEALTHY_FINAL/$MAX_NEW_CAPACITY healthy in new TG"
#               if [ "$NEW_HEALTHY_FINAL" -lt "$MAX_NEW_CAPACITY" ]; then
#                 echo " ERROR: Not all instances are healthy before final cutover!"
#                 exit 1
#               fi
#               echo " Scaling down old ASG to 0..."
#               aws autoscaling set-desired-capacity \
#                 --auto-scaling-group-name "$OLD_ASG_NAME" \
#                 --desired-capacity 0
#               echo " Deployment complete!"
#               break
#             fi

#             NEW_DESIRED=$((NEW_CAPACITY + 1))
#             if [ "$NEW_DESIRED" -gt "$MAX_NEW_CAPACITY" ]; then
#               NEW_DESIRED=$MAX_NEW_CAPACITY
#             fi

#             echo "Scaling new ASG from $NEW_CAPACITY to $NEW_DESIRED instances..."
#             aws autoscaling set-desired-capacity \
#               --auto-scaling-group-name "$NEW_ASG_NAME" \
#               --desired-capacity "$NEW_DESIRED"

#             sleep 240
#             echo "NEW TG = $NEW_TG_ARN"
#             OLD_HEALTHY=$(count_healthy_instances "$OLD_TG_ARN")
#             NEW_HEALTHY=$(count_healthy_instances "$NEW_TG_ARN")

#             echo "Healthy instances: Old TG=$OLD_HEALTHY, New TG=$NEW_HEALTHY"

#             TOTAL_HEALTHY=$((OLD_HEALTHY + NEW_HEALTHY))

#             if [ "$TOTAL_HEALTHY" -eq 0 ]; then
#               echo "ERROR: No healthy instances available"
#               exit 1
#             fi

#             NEW_WEIGHT=$((NEW_HEALTHY * 100 / TOTAL_HEALTHY))
#             OLD_WEIGHT=$((100 - NEW_WEIGHT))

#             update_traffic_weights "$OLD_WEIGHT" "$NEW_WEIGHT"

#             echo " Monitoring for 5 minutes..."
#             sleep 300

#             NEW_HEALTHY_AFTER=$(count_healthy_instances "$NEW_TG_ARN")
#             OLD_HEALTHY_AFTER=$(count_healthy_instances "$OLD_TG_ARN")

#             echo "Post-monitoring health: Old TG=$OLD_HEALTHY_AFTER, New TG=$NEW_HEALTHY_AFTER"

#             if [ "$OLD_CAPACITY" -gt 0 ]; then
#               OLD_DESIRED=$((OLD_CAPACITY - 1))
#               if [ "$OLD_DESIRED" -lt 0 ]; then
#                 OLD_DESIRED=0
#               fi
#               echo " Scaling down old ASG from $OLD_CAPACITY to $OLD_DESIRED instances..."
#               aws autoscaling set-desired-capacity \
#                 --auto-scaling-group-name "$OLD_ASG_NAME" \
#                 --desired-capacity "$OLD_DESIRED"
#             fi

#             ITERATION=$((ITERATION + 1))
#           done

#           echo ""
#           echo "========================================="
#           echo " Deployment Summary"
#           echo "========================================="
#           echo "Total iterations: $ITERATION"
#           echo "Final state:"
#           echo "  - Old ASG: $(get_asg_capacity "$OLD_ASG_NAME") instances"
#           echo "  - New ASG: $(get_asg_capacity "$NEW_ASG_NAME") instances"
#           echo "  - Old TG healthy: $(count_healthy_instances "$OLD_TG_ARN")"
#           echo "  - New TG healthy: $(count_healthy_instances "$NEW_TG_ARN")"
#           echo "========================================="

#       - name: Cleanup Old Infrastructure
#         if: success()
#         run: |
#           echo "ðŸ§¹ Cleaning up old infrastructure..."

#           if [ -z "${{ env.OLD_ASG_NAME }}" ] || [ "${{ env.OLD_ASG_NAME }}" == "null" ]; then
#             echo "No old infrastructure to clean up (first deployment)"
#             exit 0
#           fi

#           sleep 120

#           echo "Deleting old ASG: ${{ env.OLD_ASG_NAME }}"
#           aws autoscaling delete-auto-scaling-group \
#             --auto-scaling-group-name "${{ env.OLD_ASG_NAME }}" \
#             --force-delete || echo "Old ASG already deleted or doesn't exist"

#           sleep 60

#           if [ -n "${{ env.OLD_TG_ARN }}" ] && [ "${{ env.OLD_TG_ARN }}" != "null" ]; then
#             echo "Deleting old Target Group: ${{ env.OLD_TG_ARN }}"
#             aws elbv2 delete-target-group \
#               --target-group-arn "${{ env.OLD_TG_ARN }}" || echo "Old TG already deleted or doesn't exist"
#           fi

#           echo " Old infrastructure cleaned up successfully"

#   update-secrets:
#     needs: [create-new-infrastructure, progressive-rollout]
#     runs-on: ubuntu-latest
#     steps:
#       - name: Update OLD_ASG_NAME secret
#         uses: peter-evans/create-or-update-secret@v1
#         with:
#           secret-name: OLD_ASG_NAME
#           secret-value: ${{ needs.create-new-infrastructure.outputs.new_asg_name }}
#           repository: ${{ github.repository }}
#           token: ${{ secrets.GH_PAT }}

#       - name: Update OLD_TG_ARN secret
#         uses: peter-evans/create-or-update-secret@v1
#         with:
#           secret-name: OLD_TG_ARN
#           secret-value: ${{ needs.create-new-infrastructure.outputs.new_tg_arn }}
#           repository: ${{ github.repository }}
#           token: ${{ secrets.GH_PAT }}

#       - name: Deployment Success Notification
#         run: |
#           echo " Deployment completed successfully!"
#           echo "New ASG: ${{ needs.create-new-infrastructure.outputs.new_asg_name }}"
#           echo "New TG: ${{ needs.create-new-infrastructure.outputs.new_tg_arn }}"

name: Production ASG Progressive Canary Deployment

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  AWS_REGION: ap-south-1
  APP_NAME: quotes-app
  OLD_ASG_NAME: ${{ secrets.OLD_ASG_NAME }}
  OLD_TG_ARN: ${{ secrets.OLD_TG_ARN }}
  ALB_LISTENER_ARN: ${{ secrets.ALB_LISTENER_ARN }}
  LAUNCH_TEMPLATE_ID: ${{ secrets.LAUNCH_TEMPLATE_ID }}
  PRIVATE_SUBNET_IDS: ${{ secrets.PRIVATE_SUBNET_IDS }}
  DEPLOYMENT_BUCKET: ${{ secrets.DEPLOYMENT_BUCKET }}
  SECURITY_GROUP_IDS: ${{ secrets.SECURITY_GROUP_IDS }}
  TOTAL_INSTANCES: 5

jobs:
  build:
    runs-on: ubuntu-latest
    outputs:
      image_tag: ${{ steps.set_tag.outputs.image_tag }}
      launch_template_version: ${{ steps.create_lt_version.outputs.version }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set image tag
        id: set_tag
        run: |
          TAG=$(date +'%Y%m%d%H%M%S')
          echo "image_tag=$TAG" >> $GITHUB_OUTPUT
         
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Docker images
        run: |
          TAG=${{ steps.set_tag.outputs.image_tag }}
          echo " Building images with tag: $TAG"
          
          for service in db api app; do
            IMAGE_NAME="${{ secrets.DOCKER_USERNAME }}/quotes-${service}"
            echo "Building $service..."
            docker build --no-cache -t $IMAGE_NAME:${TAG} -t $IMAGE_NAME:latest $GITHUB_WORKSPACE/$service
            docker push $IMAGE_NAME:${TAG}
            docker push $IMAGE_NAME:latest
          done

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Upload deployment files to S3
        run: |
          TAG=${{ steps.set_tag.outputs.image_tag }}
          
          sed -i "s|build: ./db|image: ${{ secrets.DOCKER_USERNAME }}/quotes-db:${TAG}|g" docker-compose.yml
          sed -i "s|build: ./api|image: ${{ secrets.DOCKER_USERNAME }}/quotes-api:${TAG}|g" docker-compose.yml
          sed -i "s|build: ./app|image: ${{ secrets.DOCKER_USERNAME }}/quotes-app:${TAG}|g" docker-compose.yml

          aws s3 cp docker-compose.yml s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/
          aws s3 cp deployment/ s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/deployment/ --recursive
          aws s3 cp ./nginx-config/quotes.conf s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/

          echo "Deployment files uploaded to S3"

      - name: Create new Launch Template version with env setup and deploy
        id: create_lt_version
        run: |
          TAG=${{ steps.set_tag.outputs.image_tag }}
          
          cat > user-data.sh <<'EOF'
          #!/bin/bash
          set -ex

          LOG_FILE=/var/log/user-data.log

          echo "Starting system update..." | tee -a $LOG_FILE
          sudo apt-get update -y >> $LOG_FILE 2>&1
          sudo apt-get upgrade -y >> $LOG_FILE 2>&1

          echo "Installing docker prerequisites..." | tee -a $LOG_FILE
          sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common gnupg-agent >> $LOG_FILE 2>&1

          echo "Adding Docker GPG key and repo..." | tee -a $LOG_FILE
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - >> $LOG_FILE 2>&1
          sudo add-apt-repository \
            "deb [arch=$(dpkg --print-architecture)] https://download.docker.com/linux/ubuntu \
            $(lsb_release -cs) stable" >> $LOG_FILE 2>&1

          echo "Installing Docker engine..." | tee -a $LOG_FILE
          sudo apt-get update -y >> $LOG_FILE 2>&1
          sudo apt-get install -y docker-ce docker-ce-cli containerd.io >> $LOG_FILE 2>&1
          sudo systemctl enable docker >> $LOG_FILE 2>&1
          sudo systemctl start docker >> $LOG_FILE 2>&1

          echo "Installing Docker Compose v2..." | tee -a $LOG_FILE
          sudo rm -f /usr/local/bin/docker-compose /usr/bin/docker-compose
          sudo apt-get install -y docker-compose-plugin

          echo "Installing nginx..." | tee -a $LOG_FILE
          sudo apt-get install -y nginx >> $LOG_FILE 2>&1
          sudo systemctl enable nginx
          sudo systemctl start nginx

          echo "Installing AWS SSM agent..." | tee -a $LOG_FILE
          if ! command -v snap >/dev/null 2>&1 || ! snap list amazon-ssm-agent >/dev/null 2>&1; then
            echo "Installing Amazon SSM Agent via .deb package"
            curl "https://s3.${AWS_REGION}.amazonaws.com/amazon-ssm-${AWS_REGION}/latest/debian_amd64/amazon-ssm-agent.deb" -o "amazon-ssm-agent.deb"
            sudo dpkg -i amazon-ssm-agent.deb || sudo apt-get install -f -y
            sudo systemctl enable amazon-ssm-agent
            sudo systemctl start amazon-ssm-agent
          else
            echo "Amazon SSM Agent already installed via snap, skipping .deb install"
            sudo systemctl enable snap.amazon-ssm-agent.amazon-ssm-agent.service
            sudo systemctl start snap.amazon-ssm-agent.amazon-ssm-agent.service
          fi
          
          sudo apt-get update -y
          sudo apt-get install -y unzip curl

          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install
          aws --version

          sudo usermod -aG docker ubuntu

          echo "Creating app directory..." | tee -a $LOG_FILE
          APP_DIR=/home/ubuntu/quotes-app
          sudo mkdir -p $APP_DIR/deployment
          sudo chown -R ubuntu:ubuntu $APP_DIR
          echo "App directory created at $APP_DIR" | tee -a $LOG_FILE

          echo "Downloading deployment files from S3..." | tee -a $LOG_FILE
          aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/docker-compose.yml $APP_DIR/docker-compose.yml --region ${AWS_REGION} >> $LOG_FILE 2>&1
          aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/deployment/ $APP_DIR/deployment/ --recursive --region ${AWS_REGION} >> $LOG_FILE 2>&1
          sudo aws s3 cp s3://${DEPLOYMENT_BUCKET}/deployments/${TAG}/quotes.conf /etc/nginx/conf.d/quotes.conf --region ${AWS_REGION} >> $LOG_FILE 2>&1

          sudo chown -R ubuntu:ubuntu $APP_DIR
          sudo chmod +x $APP_DIR/deployment/*.sh

          echo "Deploying docker-compose app..." | tee -a $LOG_FILE
          cd $APP_DIR
          sudo -u ubuntu docker compose down || true >> $LOG_FILE 2>&1
          sudo -u ubuntu docker compose pull >> $LOG_FILE 2>&1
          sudo -u ubuntu docker compose up -d >> $LOG_FILE 2>&1
          sudo rm -rf /etc/nginx/sites-enabled/default
          echo "Reloading nginx..." | tee -a $LOG_FILE
          sudo systemctl reload nginx >> $LOG_FILE 2>&1

          echo "User data script completed successfully" | tee -a $LOG_FILE

          EOF

          sed -i "s|\${DEPLOYMENT_BUCKET}|${{ env.DEPLOYMENT_BUCKET }}|g" user-data.sh
          sed -i "s|\${TAG}|${TAG}|g" user-data.sh
          sed -i "s|\${AWS_REGION}|${{ env.AWS_REGION }}|g" user-data.sh
          sed -i "s|\${DOCKER_USERNAME}|${{ secrets.DOCKER_USERNAME }}|g" user-data.sh
          sed -i "s|\${DOCKER_PASSWORD}|${{ secrets.DOCKER_PASSWORD }}|g" user-data.sh

          NEW_VERSION=$(aws ec2 create-launch-template-version \
            --launch-template-id ${{ env.LAUNCH_TEMPLATE_ID }} \
            --source-version '$Latest' \
            --launch-template-data "{
              \"UserData\": \"$(base64 -w 0 user-data.sh)\",
              \"TagSpecifications\": [{
                \"ResourceType\": \"instance\",
                \"Tags\": [
                  {\"Key\": \"Name\", \"Value\": \"quotes-app-green\"},
                  {\"Key\": \"Environment\", \"Value\": \"green\"},
                  {\"Key\": \"DeploymentBatch\", \"Value\": \"${TAG}\"}
                ]
              }]
            }" \
            --query 'LaunchTemplateVersion.VersionNumber' \
            --output text)

          echo "launch_template_version=$NEW_VERSION" >> $GITHUB_OUTPUT

 
      - name: Create new Target Group
        id: create_tg
        run: |
          TG_NAME="tg-${{ github.run_number }}-${{ env.APP_NAME }}"
          TG_ARN=$(aws elbv2 create-target-group \
            --name "$TG_NAME" \
            --protocol HTTP \
            --port 80 \
            --vpc-id "${{ secrets.VPC_ID }}" \
            --health-check-path / \
            --health-check-interval-seconds 30 \
            --health-check-timeout-seconds 5 \
            --healthy-threshold-count 2 \
            --unhealthy-threshold-count 3 \
            --query 'TargetGroups[0].TargetGroupArn' \
            --output text)
          echo "tg_arn=$TG_ARN" >> $GITHUB_OUTPUT
          sleep 30

      - name: Create new Auto Scaling Group
        id: create_asg
        run: |
          ASG_NAME="asg-${{ github.run_number }}-${{ env.APP_NAME }}"
          LAUNCH_TEMPLATE_VERSION="${{ steps.create_lt_version.outputs.launch_template_version }}"
          TG_ARN="${{ steps.create_tg.outputs.tg_arn }}"

          aws autoscaling create-auto-scaling-group \
            --auto-scaling-group-name "$ASG_NAME" \
            --launch-template LaunchTemplateId=${{ env.LAUNCH_TEMPLATE_ID }},Version=$LAUNCH_TEMPLATE_VERSION \
            --min-size 1 \
            --max-size 5 \
            --desired-capacity 1 \
            --target-group-arns "$TG_ARN" \
            --vpc-zone-identifier "${{ secrets.PRIVATE_SUBNET_IDS }}" \
            --health-check-type ELB \
            --health-check-grace-period 300 \
            --termination-policies "OldestInstance" \
            --tags '[{"Key":"Name","Value":"'"$ASG_NAME"'"},{"Key":"Environment","Value":"green"}]'
        
          echo "asg_name=$ASG_NAME" >> $GITHUB_OUTPUT
          sleep 240

      - name: Debug create_tg output
        run: echo "TG ARN from step= ${{ steps.create_tg.outputs.tg_arn }}"

      - name: Set initial traffic split 80% old TG, 20% new TG
        run: |
          aws elbv2 modify-listener \
            --listener-arn ${{ env.ALB_LISTENER_ARN }} \
            --default-actions '[
              {
                "Type": "forward",
                "ForwardConfig": {
                  "TargetGroups": [
                    {
                      "TargetGroupArn": "${{ env.OLD_TG_ARN }}",
                      "Weight": 80
                    },
                    {
                      "TargetGroupArn": "${{ steps.create_tg.outputs.tg_arn }}",
                      "Weight": 20
                    }
                  ],
                  "TargetGroupStickinessConfig": {
                    "Enabled": false
                  }
                }
              }
            ]'
          sleep 30
  
  

      - name: Dynamic Progressive Rollout
        run: |
          OLD_ASG_NAME="${{ env.OLD_ASG_NAME }}"
          OLD_TG_ARN="${{ env.OLD_TG_ARN }}"
          NEW_ASG_NAME="${{ steps.create_asg.outputs.asg_name }}"
          NEW_TG_ARN="${{ steps.create_tg.outputs.tg_arn }}"
          ALB_LISTENER_ARN="${{ env.ALB_LISTENER_ARN }}"
          MAX_NEW_CAPACITY=${{ env.TOTAL_INSTANCES }}

          echo "Starting progressive rollout"
          echo "New ASG: $NEW_ASG_NAME"
          echo "New TG ARN: $NEW_TG_ARN"
          echo "Old ASG: $OLD_ASG_NAME"
          echo "Old TG ARN: $OLD_TG_ARN"

          set -e

          count_healthy_instances() {
            local TG_ARN=$1
            if [ -z "$TG_ARN" ] || [ "$TG_ARN" == "null" ]; then
              echo "0"
              return
            fi
            aws elbv2 describe-target-health --target-group-arn "$TG_ARN" --query "length(TargetHealthDescriptions[?TargetHealth.State=='healthy'])" --output text 2>/dev/null || echo "0"
          }

          get_asg_capacity() {
            local ASG_NAME=$1
            if [ -z "$ASG_NAME" ] || [ "$ASG_NAME" == "null" ]; then
              echo "0"
              return
            fi
            aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names "$ASG_NAME" --query "AutoScalingGroups[0].DesiredCapacity" --output text 2>/dev/null || echo "0"
          }

          update_traffic_weights() {
            local OLD_WEIGHT=$1
            local NEW_WEIGHT=$2
            echo "Updating traffic: Old TG=${OLD_WEIGHT}%, New TG=${NEW_WEIGHT}%"
            
            if [ "$OLD_WEIGHT" -eq 0 ]; then
              aws elbv2 modify-listener \
                --listener-arn "$ALB_LISTENER_ARN" \
                --default-actions Type=forward,TargetGroupArn="$NEW_TG_ARN"
            elif [ "$NEW_WEIGHT" -eq 0 ]; then
              aws elbv2 modify-listener \
                --listener-arn "$ALB_LISTENER_ARN" \
                --default-actions Type=forward,TargetGroupArn="$OLD_TG_ARN"
            else
              aws elbv2 modify-listener \
                --listener-arn "$ALB_LISTENER_ARN" \
                --default-actions "[
                  {
                    \"Type\": \"forward\",
                    \"ForwardConfig\": {
                      \"TargetGroups\": [
                        {
                          \"TargetGroupArn\": \"$OLD_TG_ARN\",
                          \"Weight\": $OLD_WEIGHT
                        },
                        {
                          \"TargetGroupArn\": \"$NEW_TG_ARN\",
                          \"Weight\": $NEW_WEIGHT
                        }
                      ]
                    }
                  }
                ]"
            fi
          }

          ITERATION=1
          while true; do
            echo ""
            echo "========================================="
            echo "ðŸ“ Iteration $ITERATION"
            echo "========================================="
            echo "NEW TG = $NEW_TG_ARN"
            OLD_CAPACITY=$(get_asg_capacity "$OLD_ASG_NAME")
            NEW_CAPACITY=$(get_asg_capacity "$NEW_ASG_NAME")


            echo "Current capacities: Old ASG=$OLD_CAPACITY, New ASG=$NEW_CAPACITY"


            if [ "$NEW_CAPACITY" -ge "$MAX_NEW_CAPACITY" ]; then
              echo " New ASG has reached maximum capacity ($MAX_NEW_CAPACITY)"
              echo " Performing final traffic shift to 100% new TG"
              update_traffic_weights 0 100
              echo " Waiting 3 minutes for traffic to stabilize..."
              sleep 180
              NEW_HEALTHY_FINAL=$(count_healthy_instances "$NEW_TG_ARN")
              echo "Final health check: $NEW_HEALTHY_FINAL/$MAX_NEW_CAPACITY healthy in new TG"
              if [ "$NEW_HEALTHY_FINAL" -lt "$MAX_NEW_CAPACITY" ]; then
                echo " ERROR: Not all instances are healthy before final cutover!"
                exit 1
              fi
              echo " Scaling down old ASG to 0..."
              aws autoscaling set-desired-capacity --auto-scaling-group-name "$OLD_ASG_NAME" --desired-capacity 0
              echo " Deployment complete!"
              break
            fi

            NEW_DESIRED=$((NEW_CAPACITY + 1))
            if [ "$NEW_DESIRED" -gt "$MAX_NEW_CAPACITY" ]; then
              NEW_DESIRED=$MAX_NEW_CAPACITY
            fi

            echo "Scaling new ASG from $NEW_CAPACITY to $NEW_DESIRED instances..."
            aws autoscaling set-desired-capacity --auto-scaling-group-name "$NEW_ASG_NAME" --desired-capacity "$NEW_DESIRED"

            sleep 240
            OLD_HEALTHY=$(count_healthy_instances "$OLD_TG_ARN")
            NEW_HEALTHY=$(count_healthy_instances "$NEW_TG_ARN")

            echo "Healthy instances: Old TG=$OLD_HEALTHY, New TG=$NEW_HEALTHY"

            TOTAL_HEALTHY=$((OLD_HEALTHY + NEW_HEALTHY))

            if [ "$TOTAL_HEALTHY" -eq 0 ]; then
              echo "ERROR: No healthy instances available"
              exit 1
            fi

            NEW_WEIGHT=$((NEW_HEALTHY * 100 / TOTAL_HEALTHY))
            OLD_WEIGHT=$((100 - NEW_WEIGHT))

            update_traffic_weights "$OLD_WEIGHT" "$NEW_WEIGHT"

            echo " Monitoring for 5 minutes..."
            sleep 300

            NEW_HEALTHY_AFTER=$(count_healthy_instances "$NEW_TG_ARN")
            OLD_HEALTHY_AFTER=$(count_healthy_instances "$OLD_TG_ARN")

            echo "Post-monitoring health: Old TG=$OLD_HEALTHY_AFTER, New TG=$NEW_HEALTHY_AFTER"

            if [ "$OLD_CAPACITY" -gt 0 ]; then
              OLD_DESIRED=$((OLD_CAPACITY - 1))
              if [ "$OLD_DESIRED" -lt 0 ]; then
                OLD_DESIRED=0
              fi
              echo " Scaling down old ASG from $OLD_CAPACITY to $OLD_DESIRED instances..."
              aws autoscaling set-desired-capacity --auto-scaling-group-name "$OLD_ASG_NAME" --desired-capacity "$OLD_DESIRED"
            fi

            ITERATION=$((ITERATION + 1))
          done

      - name: Cleanup Old Infrastructure
        if: success()
        run: |
          if [[ -z "${OLD_ASG_NAME}" || "${OLD_ASG_NAME}" == "null" ]]; then
            echo "No old infrastructure to clean up (first deployment)"
            exit 0
          fi

          echo "Deleting old ASG: ${OLD_ASG_NAME}"
          aws autoscaling delete-auto-scaling-group --auto-scaling-group-name "${OLD_ASG_NAME}" --force-delete || echo "Old ASG already deleted or doesn't exist"

          sleep 60

          if [[ -n "${OLD_TG_ARN}" && "${OLD_TG_ARN}" != "null" ]]; then
            echo "Deleting old Target Group: ${OLD_TG_ARN}"
            aws elbv2 delete-target-group --target-group-arn "${OLD_TG_ARN}" || echo "Old TG already deleted or doesn't exist"
          fi

          echo "Old infrastructure cleaned up successfully"
      - name: Update OLD_ASG_NAME secret
        run: |
          gh secret set OLD_ASG_NAME \
            --body "${{ steps.create_asg.outputs.asg_name }}" \
            --repo ${{ github.repository }}
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}

      - name: Update OLD_TG_ARN secret
        run: |
          gh secret set OLD_TG_ARN \
            --body "${{ steps.create_tg.outputs.tg_arn }}" \
            --repo ${{ github.repository }}
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}

      - name: Deployment Success Notification
        run: |
          echo "Deployment completed successfully!"
          echo "New ASG: ${{ steps.create_asg.outputs.asg_name }}"
          echo "New TG: ${{ steps.create_tg.outputs.tg_arn }}"